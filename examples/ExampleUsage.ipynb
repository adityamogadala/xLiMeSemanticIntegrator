{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Rake - Sample Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see an example of 'rake' algorithm for generating top 3 key phrases from the given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../utils')\n",
    "import rake\n",
    "query = \"From the engineering side, we've also been working on the ability to parallelize training of neural network\"\n",
    "rake1 = rake.Rake(\"../utils/SmartStoplist.txt\")\n",
    "vals = rake1.run(query)\n",
    "print vals[0][0] \n",
    "print vals[1][0]\n",
    "print vals[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Simple Search - Sample Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see an example of simple search used to find relevant links in News, Social Media and TV with long and short queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "sys.path.insert(0, '../search')\n",
    "import SimpleKeywordSearch\n",
    "\n",
    "xlimerec = SimpleKeywordSearch.XlimeAdvancedRecommender()\n",
    "long_query = 'From the engineering side, we have also been working on the ability to parallelize training of neural network models over multiple GPU cards simultaneously.'\n",
    "short_query = 'GPU cards'\n",
    "messagelist = xlimerec.recommender(short_query)\n",
    "print '..........Results of Short query..........'\n",
    "print messagelist\n",
    "messagelist = xlimerec.recommender(long_query)\n",
    "print '..........Results of Long query..........'\n",
    "print messagelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Document Comparison - Sample Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see an example of two documents comparison (long or short) both monolingual and cross-lingual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "sys.path.insert(0, '../docsim')\n",
    "import CompareTwoDocs\n",
    "\n",
    "text1 = \"I do not speak english\"\n",
    "text2 = \"MÃ¼nchen bietet in seinen diversen Abteilungen immer\"\n",
    "comparedoc = CompareTwoDocs.CompareDocContent()\n",
    "score = comparedoc.compare(text1,text2)   # Cross-lingual\n",
    "print '[Score between 0 and 1]: ', score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MongoDB collections for Analytics - Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import re\n",
    "class CountMongo:\n",
    "        def __init__(self,configdic):\n",
    "                self.configdict = configdic\n",
    "        def count(self):\n",
    "                if self.configdict['MongoDBPath']!=\"\":\n",
    "                        client = MongoClient(self.configdict['MongoDBPath'])\n",
    "                        if self.configdict['MongoDBUserName']!=\"\" and self.configdict['MongoDBPassword']!=\"\":\n",
    "                                client.the_database.authenticate(self.configdict['MongoDBUserName'],self.configdict['MongoDBPassword'],source=self.configdict['MongoDBStorage'])\n",
    "                                storedb = client[self.configdict['MongoDBStorage']]\n",
    "                                collection,collection1,collection2,collection3,collection4 = storedb[self.configdict['KafkaTopicTVMetadata']], storedb[self.configdict[\"KafkaTopicSocialMedia\"]],storedb[self.configdict['KafkaTopicNews']],storedb[self.configdict['KafkaTopicASR']],storedb[self.configdict['KafkaTopicSubtitles']]\n",
    "\n",
    "                print \"Total Docs in Collection [TV Metadata], [Social Media],[News],[TV ASR],[TV SubTitles]:: \", collection.find().count(), collection1.find().count(), collection2.find().count(), collection3.find().count(),collection4.find().count()\n",
    "\n",
    "def main():\n",
    "        configdict={}\n",
    "        config = '../config/Config.conf'\n",
    "        with open(config) as config_file:\n",
    "                for lines in config_file:\n",
    "                        if re.search(r'=',lines):\n",
    "                                key = lines.strip('\\n').strip().split('=')\n",
    "                                configdict[key[0]]=key[1]\n",
    "        testmongo = CountMongo(configdict)\n",
    "        testmongo.count()\n",
    "if __name__ == \"__main__\":\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
